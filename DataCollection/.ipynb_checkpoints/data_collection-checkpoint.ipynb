{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4151bd93",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875c78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f4786",
   "metadata": {},
   "source": [
    "### Important Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "832f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,max_num_hands=1, min_detection_confidence=0.5, model_complexity = 0)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "zero_hands = np.concatenate([np.zeros(21*3),np.zeros(21*3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2512af0",
   "metadata": {},
   "source": [
    "#### function to draw mediapipe landmarks on capture frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c16fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hand_landmarks(image, result):\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handslms in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, handslms, mp_hands.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(255,255,255), thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(255,51,255), thickness=1,circle_radius=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ff307",
   "metadata": {},
   "source": [
    "####  Normalizes the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd6673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(frame):\n",
    "    data = frame[:63]\n",
    "    padding = frame[63:]\n",
    "\n",
    "    x = frame[:63:3]\n",
    "    y = frame[1:63:3]\n",
    "    z = frame[2:63:3]\n",
    "\n",
    "    left = min(x)\n",
    "    right = max(x)\n",
    "    top = min(y)\n",
    "\n",
    "    image_width = 1080.0\n",
    "\n",
    "    perc_width = right - left\n",
    "    width_in_image = image_width * (right - left)\n",
    "\n",
    "    if width_in_image == 0:\n",
    "        return False\n",
    "\n",
    "    if perc_width < 0.1:\n",
    "        return False\n",
    "\n",
    "    scale_factor = 400.0 / width_in_image\n",
    "\n",
    "    for (idx, val) in enumerate(x):\n",
    "        x[idx] = round(scale_factor * (val - left), 2)\n",
    "\n",
    "    for (idx, val) in enumerate(y):\n",
    "        y[idx] = round(scale_factor * (val - top), 2)\n",
    "\n",
    "    for (idx, val) in enumerate(z):\n",
    "        z[idx] = round(scale_factor * val, 2)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cd9e9",
   "metadata": {},
   "source": [
    "#### turns the result from the landmark detector into a numpy array of:\n",
    "#### -------  (2 hands)x(21 landmarks)x(cartesian triplet)  ----------\n",
    "#### with a final shape of:\n",
    "#### ---------------------- (2 hands)x(63 points)  -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e4d7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_no_order(result):\n",
    "    if result.multi_hand_landmarks:\n",
    "        if len(result.multi_hand_landmarks) == 1:\n",
    "            hand = result.multi_hand_landmarks[0]\n",
    "\n",
    "            first_hand = np.array([[res.x, res.y, res.z] for res in hand.landmark]).flatten() \n",
    "            second_hand = np.zeros(21*3)\n",
    "        else:\n",
    "            hand1 = result.multi_hand_landmarks[0]\n",
    "            hand2 = result.multi_hand_landmarks[1]\n",
    "            first_hand = np.array([[res.x, res.y, res.z] for res in hand1.landmark]).flatten() \n",
    "            second_hand = np.array([[res.x, res.y, res.z] for res in hand2.landmark]).flatten() \n",
    "    else:\n",
    "        first_hand = np.zeros(21*3)\n",
    "        second_hand = np.zeros(21*3)\n",
    "    landmark = np.concatenate([first_hand,second_hand])\n",
    "    return landmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17970c",
   "metadata": {},
   "source": [
    "#### get mediapipe results from the captured frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a12bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cb34e",
   "metadata": {},
   "source": [
    "#### allows you to start capturing and labeling data from the right\n",
    "#### label number if there is already data in that letter\n",
    "#### ex: 50 videos in A (A0-A49), new captured data will automatically be\n",
    "#### labeled starting at A50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "411fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_val(gesture_dir):\n",
    "    vals = [i for i in os.listdir(gesture_dir) if  i != '.DS_Store']\n",
    "    return len(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c824fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFolder(folder_dir):\n",
    "    content = os.listdir(folder_dir)\n",
    "    # destroy content of folder recursively\n",
    "    for item in content:\n",
    "        item_dir = os.path.join(folder_dir,item)\n",
    "        if os.path.isdir(item_dir):\n",
    "            # if it's a folder recurse through\n",
    "            removeFolder(item_dir)\n",
    "        else:\n",
    "            # otherwise destroy and keep on chuggin'\n",
    "            os.remove(item_dir)\n",
    "    # destroy current folder and return\n",
    "    os.rmdir(folder_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861d5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureVideo(video_dir, gesture, video_count,frame_count,video_source,setup_check):\n",
    "    print(\"capturing video...\")\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    frame_num = 0\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret and (frame_num < frame_count):\n",
    "            image, results = mediapipe_detection(frame, hands)\n",
    "            draw_hand_landmarks(image,results)\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            keypoints = extract_no_order(results)\n",
    "            transformed = transform_dataframe(keypoints)\n",
    "            if (not setup_check) and (not ((keypoints == zero_hands).all())) and transformed:\n",
    "                frame_path = os.path.join(video_dir,\"{}{}_f{}\".format(gesture, video_count, frame_num))\n",
    "                np.save(frame_path, keypoints)\n",
    "                frame_num += 1\n",
    "            elif setup_check:\n",
    "                frame_num += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"frame hit\")\n",
    "            break\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52a64bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureData(gesture_dir, gesture, video_count,video_source,setup_check):\n",
    "    video_dir = os.path.join(gesture_dir, gesture + str(video_count))\n",
    "    if (not os.path.exists(video_dir)) and (not setup_check):\n",
    "        os.mkdir(video_dir)\n",
    "    print(\"capturing video #{}\".format(video_count))\n",
    "    captureVideo(video_dir, gesture, video_count,10,video_source,setup_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88973674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCaptureLoop(parent_dir, gesture, number_of_vids,video_source,setup_check):\n",
    "    gesture_dir = os.path.join(parent_dir, gesture)\n",
    "    if not os.path.exists(gesture_dir):\n",
    "        os.mkdir(gesture_dir)\n",
    "    start_val = get_starting_val(gesture_dir)\n",
    "    for i in range(start_val, start_val +number_of_vids):\n",
    "        captureData(gesture_dir, gesture, i, video_source,setup_check)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "494f7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataConfig():\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read('config.settings')\n",
    "    \n",
    "    pd = parser.get('data_collection', 'parent_directory')\n",
    "    g = parser.get('data_collection', 'gesture')\n",
    "    nv = int(parser.get('data_collection', 'number_of_vids'))\n",
    "    vs = int(parser.get('data_collection', 'video_source'))\n",
    "    sc = parser.getboolean('data_collection','setup_check')\n",
    "    return pd,g,nv,vs,sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24722e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "parent_directory, gesture, number_of_vids,video_source,setup_check = getDataConfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b947e9be",
   "metadata": {},
   "source": [
    "#### if main folder doesn't exist then make it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47714977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "making data folder...\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(parent_directory):\n",
    "    print(\"making data folder...\")\n",
    "    os.mkdir(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a874128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capturing video #0\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #1\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #2\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #3\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #4\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #5\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #6\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #7\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #8\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #9\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #10\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #11\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #12\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #13\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #14\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #15\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #16\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #17\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #18\n",
      "capturing video...\n",
      "frame hit\n",
      "capturing video #19\n",
      "capturing video...\n",
      "frame hit\n"
     ]
    }
   ],
   "source": [
    "runCaptureLoop(parent_directory, gesture, number_of_vids, video_source, setup_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06108c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
