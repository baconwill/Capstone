{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4151bd93",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "875c78c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76f4786",
   "metadata": {},
   "source": [
    "### Important Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "832f0abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "mp_hands = mp.solutions.hands\n",
    "hands = mp_hands.Hands(static_image_mode=False,max_num_hands=1, min_detection_confidence=0.5, model_complexity = 0)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "zero_hands = np.concatenate([np.zeros(21*3),np.zeros(21*3)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2512af0",
   "metadata": {},
   "source": [
    "#### function to draw mediapipe landmarks on capture frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c16fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_hand_landmarks(image, result):\n",
    "    if result.multi_hand_landmarks:\n",
    "        for handslms in result.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, handslms, mp_hands.HAND_CONNECTIONS,mp_drawing.DrawingSpec(color=(255,255,255), thickness=1,circle_radius=1),mp_drawing.DrawingSpec(color=(255,51,255), thickness=1,circle_radius=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5ff307",
   "metadata": {},
   "source": [
    "####  Normalizes the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd6673a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dataframe(frame):\n",
    "    data = frame[:63]\n",
    "    padding = frame[63:]\n",
    "\n",
    "    x = frame[:63:3]\n",
    "    y = frame[1:63:3]\n",
    "    z = frame[2:63:3]\n",
    "\n",
    "    left = min(x)\n",
    "    right = max(x)\n",
    "    top = min(y)\n",
    "\n",
    "    image_width = 1080.0\n",
    "\n",
    "    perc_width = right - left\n",
    "    width_in_image = image_width * (right - left)\n",
    "\n",
    "    if width_in_image == 0:\n",
    "        return False\n",
    "\n",
    "    if perc_width < 0.1:\n",
    "        return False\n",
    "\n",
    "    scale_factor = 400.0 / width_in_image\n",
    "\n",
    "    for (idx, val) in enumerate(x):\n",
    "        x[idx] = round(scale_factor * (val - left), 2)\n",
    "\n",
    "    for (idx, val) in enumerate(y):\n",
    "        y[idx] = round(scale_factor * (val - top), 2)\n",
    "\n",
    "    for (idx, val) in enumerate(z):\n",
    "        z[idx] = round(scale_factor * val, 2)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cd9e9",
   "metadata": {},
   "source": [
    "#### turns the result from the landmark detector into a numpy array of:\n",
    "#### -------  (2 hands)x(21 landmarks)x(cartesian triplet)  ----------\n",
    "#### with a final shape of:\n",
    "#### ---------------------- (2 hands)x(63 points)  -------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e4d7e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_no_order(result):\n",
    "    if result.multi_hand_landmarks:\n",
    "        if len(result.multi_hand_landmarks) == 1:\n",
    "            hand = result.multi_hand_landmarks[0]\n",
    "\n",
    "            first_hand = np.array([[res.x, res.y, res.z] for res in hand.landmark]).flatten() \n",
    "            second_hand = np.zeros(21*3)\n",
    "        else:\n",
    "            hand1 = result.multi_hand_landmarks[0]\n",
    "            hand2 = result.multi_hand_landmarks[1]\n",
    "            first_hand = np.array([[res.x, res.y, res.z] for res in hand1.landmark]).flatten() \n",
    "            second_hand = np.array([[res.x, res.y, res.z] for res in hand2.landmark]).flatten() \n",
    "    else:\n",
    "        first_hand = np.zeros(21*3)\n",
    "        second_hand = np.zeros(21*3)\n",
    "    landmark = np.concatenate([first_hand,second_hand])\n",
    "    return landmark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a17970c",
   "metadata": {},
   "source": [
    "#### get mediapipe results from the captured frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a12bd58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image.flags.writeable = False\n",
    "    results = model.process(image)\n",
    "    image.flags.writeable = True\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "    return image, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2cb34e",
   "metadata": {},
   "source": [
    "#### allows you to start capturing and labeling data from the right\n",
    "#### label number if there is already data in that letter\n",
    "#### ex: 50 videos in A (A0-A49), new captured data will automatically be\n",
    "#### labeled starting at A50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411fb77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_starting_val(gesture_dir):\n",
    "    vals = [i for i in os.listdir(gesture_dir) if  i != '.DS_Store']\n",
    "    return len(vals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c824fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFolder(folder_dir):\n",
    "    content = os.listdir(folder_dir)\n",
    "    # destroy content of folder recursively\n",
    "    for item in content:\n",
    "        item_dir = os.path.join(folder_dir,item)\n",
    "        if os.path.isdir(item_dir):\n",
    "            # if it's a folder recurse through\n",
    "            removeFolder(item_dir)\n",
    "        else:\n",
    "            # otherwise destroy and keep on chuggin'\n",
    "            os.remove(item_dir)\n",
    "    # destroy current folder and return\n",
    "    os.rmdir(folder_dir)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "861d5bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureVideo(video_dir, gesture, video_count,frame_count,video_source,setup_check):\n",
    "    print(\"capturing video...\")\n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    frame_num = 0\n",
    "    while cap.isOpened():\n",
    "        ret,frame = cap.read()\n",
    "        if ret and (frame_num < frame_count):\n",
    "            image, results = mediapipe_detection(frame, hands)\n",
    "            draw_hand_landmarks(image,results)\n",
    "            cv2.imshow('OpenCV Feed', image)\n",
    "            keypoints = extract_no_order(results)\n",
    "            transformed = transform_dataframe(keypoints)\n",
    "            if (not setup_check) and (not ((keypoints == zero_hands).all())) and transformed:\n",
    "                frame_path = os.path.join(video_dir,\"{}{}_f{}\".format(gesture, video_count, frame_num))\n",
    "                np.save(frame_path, keypoints)\n",
    "                frame_num += 1\n",
    "            elif setup_check:\n",
    "                frame_num += 1\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            print(\"frame hit\")\n",
    "            break\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52a64bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def captureData(gesture_dir, gesture, video_count,video_source,setup_check):\n",
    "    video_dir = os.path.join(gesture_dir, gesture + str(video_count))\n",
    "    if (not os.path.exists(video_dir)) and (not setup_check):\n",
    "        os.mkdir(video_dir)\n",
    "    print(\"capturing video #{}\".format(video_count))\n",
    "    captureVideo(video_dir, gesture, video_count,10,video_source,setup_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88973674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCaptureLoop(parent_dir, gesture, number_of_vids,video_source,setup_check):\n",
    "    gesture_dir = os.path.join(parent_dir, gesture)\n",
    "    if not os.path.exists(gesture_dir):\n",
    "        os.mkdir(gesture_dir)\n",
    "    start_val = get_starting_val(gesture_dir)\n",
    "    for i in range(start_val, start_val +number_of_vids):\n",
    "        captureData(gesture_dir, gesture, i, video_source,setup_check)\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "494f7bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataConfig():\n",
    "    parser = configparser.ConfigParser()\n",
    "    parser.read('config.settings')\n",
    "    \n",
    "    pd = parser.get('[data_collection]', 'parent_directory')\n",
    "    g = parser.get('[data_collection]', 'gesture')\n",
    "    nv = int(parser.get('[data_collection]', 'number_of_vids'))\n",
    "    vs = int(parser.get('[data_collection]', 'video_source'))\n",
    "    sc = parser.getboolean('[data_collection]','setup_check')\n",
    "    return pd,g,nv,vs,sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24722e88",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSectionError",
     "evalue": "No section: '[data_collection]'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSectionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xm/2mgsgbps04q0wf1_zxx26_280000gn/T/ipykernel_30414/3096928963.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mparent_directory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgesture\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_vids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvideo_source\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msetup_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetDataConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/xm/2mgsgbps04q0wf1_zxx26_280000gn/T/ipykernel_30414/3456839826.py\u001b[0m in \u001b[0;36mgetDataConfig\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'config.settings'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[data_collection]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'parent_directory'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[data_collection]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gesture'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[data_collection]'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'number_of_vids'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/configparser.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, section, option, raw, vars, fallback)\u001b[0m\n\u001b[1;32m    779\u001b[0m         \"\"\"\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m             \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unify_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfallback\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0m_UNSET\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/configparser.py\u001b[0m in \u001b[0;36m_unify_values\u001b[0;34m(self, section, vars)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msection\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault_section\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1152\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mNoSectionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1153\u001b[0m         \u001b[0;31m# Update with the entry specific variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0mvardict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSectionError\u001b[0m: No section: '[data_collection]'"
     ]
    }
   ],
   "source": [
    "parent_directory, gesture, number_of_vids,video_source,setup_check = getDataConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc437165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
